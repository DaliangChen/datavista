📌 使用场景（When to Use）

LDA 和 QDA 都是分类模型，适用于：

- 监督学习分类任务：当目标是根据特征将样本分类到不同类别。
- 多类分类问题：适用于两个或多个类的情形。
- 特征之间服从高斯分布的情形尤为有效。

区别：

- LDA（线性判别分析）：

  - 类内协方差矩阵假设为 相同（线性边界）。
  - 适用于特征之间的方差结构相近的情况。

- QDA（二次判别分析）：

  - 每个类有自己的协方差矩阵（非线性边界）。
  - 更灵活，但对样本数要求更高。

📌 基本原理（How It Works）

共同点：

- 两者都基于 贝叶斯定理，对每个类估计其概率密度函数，然后使用最大后验概率（MAP）进行预测。
- 假设数据在每个类别中都符合 多元高斯分布。

LDA 原理：

1. 估计所有类的 共同协方差矩阵 和均值向量。
2. 假设类条件协方差矩阵 相同。
3. 分类边界是 线性的（超平面）。

QDA 原理：

1. 每个类分别估计 自己的协方差矩阵 和均值向量。
2. 不假设类条件协方差相等。
3. 分类边界是 二次曲线，更复杂。

📌 注意事项（Caveats）

1. 高斯假设要求：

   - LDA 和 QDA 都假设特征在每个类别中服从正态分布。如果这个假设偏离较大，性能可能受影响。

2. 样本量要求：

   - QDA 由于需要为每个类估计一个协方差矩阵，因此在特征多而样本少时，容易过拟合。
   - LDA 更稳健，尤其在样本数量不多时优于 QDA。

3. 数值稳定性：

   - 协方差矩阵必须是非奇异的（可逆）。否则会导致数值问题。

4. 特征缩放：

   - 不强制要求标准化，但如果特征单位差异大，最好进行缩放以改善协方差估计。

5. 分类边界差异：

   - LDA 创建线性边界，适合线性可分问题；
   - QDA 边界可弯曲，适合复杂分布，但计算代价更高。
