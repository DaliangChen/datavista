📌 使用场景（When to Use）

Kernel Ridge Regression 适用于：

- 非线性回归问题：当线性模型效果不佳时，通过核函数进行非线性映射。
- 中小型数据集：因其复杂度较高，适合样本量不大的场景。
- 函数估计或拟合：如在信号处理、图像重建、天气预测等连续输出变量的预测任务中。
- 需要平衡拟合精度和复杂度的任务：岭回归项可以控制过拟合。

📌 基本原理（How It Works）

1. Ridge Regression 基础

- 在线性回归的基础上，加上一个 L2 正则化项（惩罚权重大小），防止过拟合。

2. 核技巧（Kernel Trick）

- 将原始输入通过核函数隐式映射到高维空间。
- 在这个高维空间中，进行岭回归，从而解决非线性问题。
- 常用核函数：

  - 线性核 `linear`
  - 高斯径向基核 `rbf`
  - 多项式核 `polynomial`
  - 拉普拉斯核 `laplacian`
  - Sigmoid 核

3. 公式表达

预测函数为：

$$
\hat{y}(x) = \sum_{i=1}^{n} \alpha_i K(x, x_i)
$$

其中：

- $K(x, x_i)$：核函数
- $\alpha$：通过求解线性系统得到的系数向量

4. 训练过程

- 计算核矩阵 $K$
- 求解线性系统：

$$
(K + \alpha I) \alpha = y
$$

其中 $\alpha$ 为正则化参数，$I$ 为单位矩阵。

📌 注意事项（Caveats）

1. 计算复杂度高：

   - 核矩阵大小为 $n \times n$，因此内存和计算成本为 $O(n^2)$ 和 $O(n^3)$，不适合大数据集。
   - 适合 几千个样本以内 的问题。

2. 需要选择合适的核函数和超参数：

   - 如 `alpha`（正则强度）、`gamma`（核参数），需通过交叉验证等手段调参。
   - 核函数选择不当，可能导致欠拟合或过拟合。

3. 缺乏稀疏性：

   - 与支持向量回归（SVR）不同，Kernel Ridge Regression 不会产生稀疏解（所有训练样本都参与预测）。

4. 对特征标准化敏感：

   - 尤其是使用 RBF 或多项式核时，建议在使用前对输入特征进行标准化处理。

5. 不适合高维稀疏输入（如文本）：

   - 因为它需要显式计算核矩阵，而在这类数据中，线性模型（如 SGD、线性 SVR）会更高效。
