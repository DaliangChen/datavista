📌 使用场景

- 处理 不同分布类型的回归问题，不仅限于正态分布（比如二项分布、泊松分布等）。
- 适合对响应变量服从指数族分布的情况进行建模。
- 应用范围广泛，包括：

  - 线性回归
  - 逻辑回归（分类问题）
  - 泊松回归（计数数据）

- 需要灵活建模数据的不同类型和链接函数。
- 大规模数据集，Scikit-learn 的 `HistGradientBoosting` 和其他优化实现适合高效训练。

📌 基本原理

- GLM 是线性模型的推广，假设响应变量 $y$ 的分布属于指数族，比如正态分布、二项分布、泊松分布等。

- 通过一个链接函数 $g(\cdot)$ 把响应变量的期望值 $\mu = E(y)$ 与线性预测 $\eta = X\beta$ 关联起来：

  $$
  g(\mu) = \eta = X\beta
  $$

- 这种方法使得模型能够处理非正态的响应变量。

- Scikit-learn 实现中使用的是 分布族和链接函数的组合，如：

  - 高斯分布 + 恒等链接（普通线性回归）
  - 二项分布 + 对数几率链接（逻辑回归）
  - 泊松分布 + 对数链接（计数回归）

- 模型参数通过最大似然估计进行拟合。

📌 注意事项

1. 需选择合适的分布族和链接函数：

   - 不同任务对应不同分布和链接函数，选错会导致模型表现差。

2. 对数据分布有假设要求：

   - 例如泊松回归假设计数数据均值和方差相等（均值-方差关系），不满足时效果差。

3. 参数估计可能需要迭代算法：

   - 迭代加权最小二乘（IWLS）是常见方法，可能计算开销较大。

4. 模型可解释性强，适合统计分析和解释性需求高的场景。

5. 在高维数据下，建议结合正则化：

   - 可使用 ElasticNet、L1、L2 正则避免过拟合。

6. 数据预处理重要：

   - 特征标准化有助于提高模型收敛速度和稳定性。

7. Scikit-learn 的 GLM 支持分布族有限，具体可查文档；复杂分布可能需要专门统计软件。
