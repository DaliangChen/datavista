📌 使用场景

- 适用于大规模在线学习，尤其是在数据流和增量训练场景。
- 适合二分类和多分类问题，以及回归任务。
- 需要模型快速响应新数据，且保证一定稳定性和鲁棒性的场景。
- 应对概念漂移（数据分布随时间变化）问题。
- 当对模型更新的“被动”与“激进”策略有需求时，如文本分类、广告点击预测等。

📌 基本原理

- 被动-激进算法是一类在线学习算法，目标是在接收到新样本时尽可能保持原模型（被动），但又必须对误差较大的样本做出较大调整（激进）。

- 每一步，模型尝试解决如下优化问题：

  $$
  \min_w \frac{1}{2} \| w - w_{t} \|^2
  $$

  在保证新样本预测误差在容忍范围内的前提下，使模型权重变化最小。

- 损失函数常用 hinge loss（分类）或 ε-insensitive loss（回归）。

- 通过求解该优化问题，权重更新步长自适应计算。

- 保持模型的稀疏性和稳定性。

- 支持`PassiveAggressiveClassifier`（分类）和`PassiveAggressiveRegressor`（回归）。

📌 注意事项

1. 适合在线和增量学习，但不是批量学习的最佳选择。
2. 需要调节参数 `C`：

   - 控制更新的激进程度，值大则对错误样本调整更激进。

3. 对特征预处理敏感：

   - 特征缩放能帮助算法更快收敛且表现更好。

4. 不能直接提供概率输出：

   - 输出的是决策函数值或类别标签。

5. 适合数据随时间动态变化（概念漂移），但对非常嘈杂数据敏感，可能导致模型不稳定。
6. 相比传统的批量训练方法，通常训练速度更快，适合实时系统。
7. 不适合极度非线性、复杂的模式识别问题（因为本质是线性模型）。
